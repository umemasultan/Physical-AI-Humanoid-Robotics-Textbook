# Implementation Plan: Textbook Generation

**Branch**: `feature/textbook-generation` | **Date**: 2025-12-24 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/textbook-generation/spec.md`

---

## Summary

Build a 6-chapter AI-native textbook on Physical AI & Humanoid Robotics using Docusaurus with integrated RAG chatbot. Free-tier infrastructure only: GitHub Pages (frontend), Vercel/Railway (backend), Qdrant Cloud (vectors), Groq (LLM).

---

## Technical Context

**Language/Version**: TypeScript 5.x (frontend), Python 3.11+ (backend)
**Primary Dependencies**: Docusaurus 3.x, React 18, FastAPI, sentence-transformers, qdrant-client
**Storage**: Qdrant Cloud (vectors), SQLite (query logs - optional)
**Testing**: Vitest (frontend), pytest (backend)
**Target Platform**: Web (GitHub Pages + serverless backend)
**Project Type**: Web application (frontend + backend)
**Performance Goals**: <2s page load, <3s RAG response, Lighthouse >90
**Constraints**: $0/month infrastructure, no GPU, CPU-only embeddings
**Scale/Scope**: 6 chapters, ~25,000 words total, 100 concurrent users

---

## Constitution Check

| Principle | Status | Notes |
|-----------|--------|-------|
| Simplicity First | PASS | Minimal stack, no over-engineering |
| Free-Tier Architecture | PASS | All services have free tiers |
| Content Accuracy | PENDING | Requires content review |
| RAG Fidelity | PASS | 0.7 threshold, strict prompting |
| Clean UI/UX | PASS | Docusaurus defaults + minimal custom |
| Minimalist Content | PASS | 6 chapters only |

---

## Project Structure

```text
physical-ai-textbook/
├── .github/
│   └── workflows/
│       ├── deploy-frontend.yml    # GitHub Pages deployment
│       └── deploy-backend.yml     # Backend deployment
├── frontend/                      # Docusaurus site
│   ├── docs/                      # MDX chapters
│   │   ├── 01-intro-physical-ai/
│   │   │   └── index.mdx
│   │   ├── 02-humanoid-basics/
│   │   │   └── index.mdx
│   │   ├── 03-ros2-fundamentals/
│   │   │   └── index.mdx
│   │   ├── 04-digital-twin/
│   │   │   └── index.mdx
│   │   ├── 05-vla-systems/
│   │   │   └── index.mdx
│   │   ├── 06-capstone/
│   │   │   └── index.mdx
│   │   └── glossary.mdx
│   ├── src/
│   │   ├── components/
│   │   │   ├── ChatPanel/
│   │   │   │   ├── index.tsx
│   │   │   │   ├── ChatMessage.tsx
│   │   │   │   └── ChatInput.tsx
│   │   │   └── SelectToAsk/
│   │   │       └── index.tsx
│   │   ├── hooks/
│   │   │   └── useChat.ts
│   │   ├── css/
│   │   │   └── custom.css
│   │   └── theme/
│   │       └── Root.tsx           # Chat panel wrapper
│   ├── static/
│   │   ├── img/
│   │   └── diagrams/
│   ├── docusaurus.config.ts
│   ├── sidebars.ts
│   ├── package.json
│   └── tsconfig.json
├── backend/                       # FastAPI RAG service
│   ├── app/
│   │   ├── __init__.py
│   │   ├── main.py
│   │   ├── config.py
│   │   ├── routers/
│   │   │   ├── __init__.py
│   │   │   └── chat.py
│   │   ├── services/
│   │   │   ├── __init__.py
│   │   │   ├── embeddings.py
│   │   │   ├── retrieval.py
│   │   │   └── generation.py
│   │   └── models/
│   │       ├── __init__.py
│   │       └── schemas.py
│   ├── scripts/
│   │   ├── embed_content.py       # Build-time embedding
│   │   └── test_queries.py        # RAG validation
│   ├── tests/
│   │   ├── test_chat.py
│   │   ├── test_retrieval.py
│   │   └── test_embeddings.py
│   ├── requirements.txt
│   ├── Dockerfile
│   └── .env.example
├── content/                       # Raw content for embedding
│   └── chapters/                  # Extracted markdown for RAG
├── specs/
│   └── textbook-generation/
│       ├── spec.md
│       ├── plan.md                # This file
│       └── tasks.md               # Generated by /sp.tasks
├── .specify/
├── history/
├── .gitignore
├── README.md
└── CLAUDE.md
```

---

## Execution Plan

### Phase 0: Project Setup
**Purpose**: Initialize repository structure and development environment

**Tasks**:
- Create folder structure as defined above
- Initialize Docusaurus project in `frontend/`
- Initialize Python project in `backend/`
- Configure `.gitignore` for Node, Python, and IDE files
- Create `.env.example` with required variables
- Set up GitHub repository (if not exists)

**Outputs**:
- `frontend/package.json` with Docusaurus dependencies
- `backend/requirements.txt` with FastAPI dependencies
- Working `npm run start` and `uvicorn` locally
- Git repository initialized with initial commit

**Verification**:
- [ ] `cd frontend && npm install && npm run start` opens localhost:3000
- [ ] `cd backend && pip install -r requirements.txt && uvicorn app.main:app` runs

---

### Phase 1: Docusaurus Frontend Shell
**Purpose**: Build static textbook UI with placeholder content

**Tasks**:
- Configure `docusaurus.config.ts` with site metadata
- Configure `sidebars.ts` for auto-generated sidebar
- Create placeholder MDX files for all 6 chapters
- Add chapter template with: objectives, prerequisites, content, exercise, summary
- Install and configure local search plugin (`@easyops-cn/docusaurus-search-local`)
- Add custom CSS for clean typography
- Verify mobile responsiveness

**Outputs**:
- 6 placeholder chapter files in `docs/`
- Auto-generated sidebar navigation
- Working local search (Ctrl+K)
- Mobile-responsive layout

**Verification**:
- [ ] `npm run build` succeeds with 0 errors
- [ ] All 6 chapters accessible via sidebar
- [ ] Search finds placeholder content
- [ ] Site renders correctly at 375px width

---

### Phase 2: Chapter Content Creation
**Purpose**: Write all 6 chapters with educational content

**Tasks**:
- Write Chapter 1: Introduction to Physical AI (~3500 words)
- Write Chapter 2: Basics of Humanoid Robotics (~4000 words)
- Write Chapter 3: ROS 2 Fundamentals (~4500 words)
- Write Chapter 4: Digital Twin Simulation (~4000 words)
- Write Chapter 5: Vision-Language-Action Systems (~3500 words)
- Write Chapter 6: Capstone Pipeline (~4000 words)
- Create diagrams (minimum 2 per chapter, 12 total)
- Add code examples with syntax highlighting
- Create glossary with linked terms
- Test all code examples for correctness

**Outputs**:
- 6 complete MDX chapter files (~23,500 words total)
- 12+ diagrams in `static/diagrams/`
- `glossary.mdx` with 30+ terms
- All code examples tested and annotated

**Verification**:
- [ ] Each chapter has: objectives, prerequisites, 3+ sections, exercise, summary
- [ ] All code blocks have syntax highlighting and copy button
- [ ] Diagrams render correctly on desktop and mobile
- [ ] Glossary terms link to relevant chapters

---

### Phase 3: RAG Backend Core
**Purpose**: Build FastAPI backend with embedding and retrieval

**Tasks**:
- Create FastAPI app structure (`app/main.py`)
- Implement Pydantic schemas (`models/schemas.py`)
- Implement embedding service using `sentence-transformers` (all-MiniLM-L6-v2)
- Implement Qdrant retrieval service with similarity search
- Implement LLM generation service (Groq API)
- Create `/api/chat` endpoint with full RAG pipeline
- Create `/api/health` endpoint
- Add rate limiting (10 req/min per IP)
- Add CORS configuration for frontend domain
- Write unit tests for each service

**Outputs**:
- Working FastAPI server with RAG pipeline
- `POST /api/chat` returns answers with citations
- `GET /api/health` returns service status
- Test coverage >80% for backend

**Verification**:
- [ ] `pytest` passes all tests
- [ ] `/api/health` returns `{"status": "healthy"}`
- [ ] `/api/chat` with "What is ROS 2?" returns answer with Chapter 3 citation
- [ ] Rate limiting blocks 11th request within 1 minute

---

### Phase 4: Content Embedding Pipeline
**Purpose**: Embed textbook content into Qdrant for retrieval

**Tasks**:
- Create `scripts/embed_content.py` to:
  - Parse MDX files from `frontend/docs/`
  - Extract text content (strip MDX syntax)
  - Chunk at 512 tokens with 50-token overlap
  - Generate embeddings using all-MiniLM-L6-v2
  - Store in Qdrant with metadata (chapter, section, heading)
- Set up Qdrant Cloud collection (free tier)
- Run embedding pipeline on all chapters
- Create `scripts/test_queries.py` for validation
- Test retrieval with 10 sample queries

**Outputs**:
- `embed_content.py` script
- Qdrant collection with all chapter embeddings
- `test_queries.py` with 10 validation queries
- Documentation for re-running embeddings

**Verification**:
- [ ] Script completes without errors
- [ ] Qdrant collection contains expected chunk count (~200-300 chunks)
- [ ] 9/10 test queries return relevant chunks
- [ ] Embedding time <5 minutes total

---

### Phase 5: Chatbot UI Integration
**Purpose**: Build chat panel component and integrate with backend

**Tasks**:
- Create `ChatPanel` component (slide-in desktop, full-screen mobile)
- Create `ChatMessage` component (user/assistant bubbles)
- Create `ChatInput` component with send button
- Implement `useChat` hook for state management
- Add chat toggle button to Docusaurus theme
- Implement typing indicator during API call
- Handle error states (timeout, rate limit, backend down)
- Store chat history in sessionStorage
- Style for dark/light mode compatibility

**Outputs**:
- Functional chat panel in Docusaurus
- Real-time responses with source citations
- Error handling with user-friendly messages
- Session-persistent chat history

**Verification**:
- [ ] Chat opens/closes smoothly on desktop and mobile
- [ ] Questions receive answers within 3 seconds
- [ ] Source citations display correctly
- [ ] Chat history persists on page navigation (within session)

---

### Phase 6: Select-to-Ask Feature
**Purpose**: Enable text selection to ask AI for explanation

**Tasks**:
- Create `SelectToAsk` component
- Detect text selection events on page
- Show tooltip with "Ask AI" button near selection
- On click, open chat panel with pre-filled query: "Explain: [selected text]"
- Handle long selections (truncate at 500 chars)
- Add mobile support via long-press (or skip for v1)

**Outputs**:
- Working select-to-ask on desktop
- Integration with ChatPanel component

**Verification**:
- [ ] Selecting text shows tooltip
- [ ] Clicking "Ask AI" opens chat with correct query
- [ ] Long text is truncated appropriately

---

### Phase 7: Deployment Pipeline
**Purpose**: Deploy frontend to GitHub Pages, backend to free tier

**Tasks**:
- Create GitHub Actions workflow for frontend:
  - Build Docusaurus on push to `main`
  - Deploy to GitHub Pages
- Create deployment for backend:
  - Option A: Vercel (recommended for simplicity)
  - Option B: Railway
  - Option C: Render
- Configure environment variables in deployment platform
- Set up custom domain (optional)
- Configure CORS for production domain
- Test full pipeline end-to-end

**Outputs**:
- Live frontend at `https://<user>.github.io/<repo>/`
- Live backend at `https://<app>.vercel.app/`
- Automated deployments on push

**Verification**:
- [ ] Push to `main` triggers frontend deployment
- [ ] Frontend loads at GitHub Pages URL
- [ ] Backend `/api/health` returns healthy
- [ ] Chat works on production site

---

### Phase 8: Testing & Polish
**Purpose**: Ensure quality and fix edge cases

**Tasks**:
- Run Lighthouse audit on all pages
- Fix accessibility issues (if score <90)
- Fix performance issues (if score <90)
- Test 10 in-book queries for correct citations
- Test 5 out-of-book queries for "not found" response
- Test mobile experience on real device
- Review and fix any UI issues
- Update README with setup instructions
- Create CONTRIBUTING.md (optional)

**Outputs**:
- Lighthouse scores >90 for performance and accessibility
- All test queries pass
- README with local setup and deployment instructions

**Verification**:
- [ ] Lighthouse performance >90
- [ ] Lighthouse accessibility >90
- [ ] 10/10 in-book queries correct
- [ ] 5/5 out-of-book queries return "not found"
- [ ] README instructions work from scratch

---

### Phase 9 (Optional): Enhancements
**Purpose**: Add P3 features if time permits

**Tasks**:
- **Urdu Translation**:
  - Set up Docusaurus i18n
  - Translate Chapter 1 as proof-of-concept
  - Add language toggle
- **Personalization**:
  - Add localStorage-based bookmarks
  - Add inline notes feature
  - Create "My Notes" page

**Outputs**:
- (If Urdu) Bilingual Chapter 1
- (If Personalization) Working bookmarks and notes

**Verification**:
- [ ] Language toggle switches content
- [ ] Bookmarks persist across sessions

---

## Phase Dependencies

```
Phase 0 ─────────────────────────────────────────────────────────────┐
    │                                                                │
    ▼                                                                │
Phase 1 (Frontend Shell)                                             │
    │                                                                │
    ├──────────────────────┐                                         │
    │                      │                                         │
    ▼                      ▼                                         │
Phase 2 (Content)    Phase 3 (Backend)                               │
    │                      │                                         │
    └──────────┬───────────┘                                         │
               │                                                     │
               ▼                                                     │
         Phase 4 (Embedding)                                         │
               │                                                     │
               ▼                                                     │
         Phase 5 (Chat UI)                                           │
               │                                                     │
               ▼                                                     │
         Phase 6 (Select-to-Ask)                                     │
               │                                                     │
               ▼                                                     │
         Phase 7 (Deployment) ◄──────────────────────────────────────┘
               │
               ▼
         Phase 8 (Testing)
               │
               ▼
         Phase 9 (Optional)
```

**Parallelization**: Phase 2 (Content) and Phase 3 (Backend) can run in parallel after Phase 1.

---

## Risk Mitigation Plan

| Risk | Trigger | Mitigation |
|------|---------|------------|
| Qdrant free tier limit | >1GB vectors | Reduce chunk overlap; summarize long sections |
| Groq rate limit hit | >30 req/min | Implement request queue; add retry with backoff |
| GitHub Pages build fails | Complex MDX | Simplify components; test locally first |
| RAG hallucination | Wrong citations | Lower similarity threshold; stricter prompts |
| Slow embeddings | >10 min | Pre-compute locally; cache in repo |

---

## Environment Variables

### Backend (`.env`)
```
QDRANT_URL=https://xxx.qdrant.io
QDRANT_API_KEY=xxx
GROQ_API_KEY=xxx
EMBEDDING_MODEL=all-MiniLM-L6-v2
CORS_ORIGINS=https://user.github.io
RATE_LIMIT_PER_MINUTE=10
```

### Frontend (build-time)
```
REACT_APP_API_URL=https://app.vercel.app
```

---

## Acceptance Checklist

**Core Requirements**:
- [ ] 6 chapters render with correct structure
- [ ] Sidebar auto-generates from folder structure
- [ ] Local search works (Ctrl+K)
- [ ] Chat panel opens and closes
- [ ] RAG returns answers with citations
- [ ] "Not found" for out-of-scope queries
- [ ] Mobile responsive (375px)
- [ ] GitHub Pages deployment works
- [ ] Backend deployed and healthy
- [ ] $0/month infrastructure

**Quality Gates**:
- [ ] Lighthouse performance >90
- [ ] Lighthouse accessibility >90
- [ ] All code examples syntax highlighted
- [ ] Copy button works on code blocks
- [ ] No console errors in production

---

## Timeline Estimate

| Phase | Effort Level |
|-------|--------------|
| Phase 0: Setup | Low |
| Phase 1: Frontend Shell | Low |
| Phase 2: Content | High (most time here) |
| Phase 3: Backend | Medium |
| Phase 4: Embedding | Low |
| Phase 5: Chat UI | Medium |
| Phase 6: Select-to-Ask | Low |
| Phase 7: Deployment | Low |
| Phase 8: Testing | Medium |
| Phase 9: Optional | Variable |

**Critical Path**: Phase 2 (Content Creation) is the bottleneck. Backend work can proceed in parallel.

---

## Next Steps

1. Run `/sp.tasks` to generate detailed task breakdown
2. Begin Phase 0: Project Setup
3. Parallelize Phase 2 (Content) and Phase 3 (Backend) once Phase 1 complete
